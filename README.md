# Credit-Card-Default-Risk-Predictor
To build, evaluate, and deploy an interpretable credit risk model that predicts the probability of credit card default and converts it into actionable risk categories, using industry-aligned modeling and deployment practices.

1Ô∏è‚É£ PROBLEM STATEMENT

Financial institutions must identify customers who are likely to default before losses occur.
The challenge is to:

Capture behavioral risk patterns

Maintain model interpretability

Ensure governance & deployment readiness

This project simulates a real banking risk analytics workflow, from raw data to a deployed application.

2Ô∏è‚É£ DATASET

Dataset: UCI Credit Card Default Dataset

Records: 30,000 customers

Target Variable: DEFAULT (1 = default, 0 = non-default)

Key Feature Groups

Exposure: Credit limit

Behavior: Payment delays, repayment volatility

Utilization: Credit usage vs limit

Demographics: Age, education, marital status

3Ô∏è‚É£ DATA CLEANING & PREPROCESSING

Steps Performed

Renamed target variable for clarity

Removed non-informative ID column

Cleaned invalid categorical values

Validated age and payment fields

Ensured no missing values

Important Design Choice

Behavior > Demographics

Behavioral variables were prioritized, aligning with real credit risk policy.

4Ô∏è‚É£ FEATURE ENGINEERING (CORE STRENGTH)

Created domain-driven features instead of using raw monthly data:

Feature	Description

CREDIT_UTILIZATION	Avg bill / credit limit

PAYMENT_RATIO	Avg payment / avg bill

MAX_DELAY	Worst delinquency

AVG_DELAY	Persistent delinquency

DELINQUENCY_TREND	Worsening vs improving behavior

DELAY_STD	Payment volatility

üëâ These features make the model interpretable and stable.

5Ô∏è‚É£ MODELING STRATEGY

Why Logistic Regression (Primary Model)

Interpretable coefficients

Regulator-friendly

Stable and explainable

Industry standard in credit risk

Challengers Evaluated

Decision Tree

Random Forest

Voting Ensemble

Stacking Ensemble

Key Finding:
Ensembles marginally improved ROC-AUC but did not justify loss of interpretability.

‚úî Logistic Regression retained as production model

‚úî Trees & ensembles used for benchmarking only

6Ô∏è‚É£ MODEL EVALUATION

Metrics Used

ROC-AUC (primary)

Default Recall (business-critical)

Precision, Accuracy (secondary)

Final Logistic Regression Performance

ROC-AUC: ~0.73

Default Recall: ~61%

Interpretation: Risk-conservative and business-aligned

7Ô∏è‚É£ THRESHOLD & RISK BUCKETING

Instead of raw probabilities, predictions were mapped to actionable risk buckets:

Probability -	Risk - Level -	Business Action
< 0.35 -	Low -	Normal - monitoring
0.35 ‚Äì 0.60 -	Medium -	Reminders & monitoring
> 0.60 -	High -	Proactive risk controls

This converts ML output ‚Üí decision support.

8Ô∏è‚É£ DEPLOYMENT ARCHITECTURE

Deployment Principles

Deploy only Logistic Regression

Keep preprocessing inside pipeline

Ensure version compatibility

Business-friendly UI

Tech Stack

Python

scikit-learn

Streamlit

joblib

9Ô∏è‚É£ STREAMLIT APPLICATION

App Features

Human-readable inputs (Education, Marital Status, Gender)

Probability-based prediction

Clear risk classification

Business action recommendations

Output Example

Default Probability: 50.3%

Risk: Medium

Action: Monitor closely

üîü FINAL OUTCOME

‚úî End-to-end ML lifecycle

‚úî Bank-grade modeling decisions

‚úî Deployed & usable application

‚úî Interview-ready project
